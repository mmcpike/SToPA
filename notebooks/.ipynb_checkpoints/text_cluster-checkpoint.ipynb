{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b506f463-a10d-4232-a9a4-f0b2909a9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import enchant\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a95cff13-1a00-49f7-9590-989b055079e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"C:/Users/mlmcp/stopa/data/2020_parquet_logs/\"\n",
    "filelist = os.listdir(filepath)\n",
    "# shortlist = filelist[0:9]\n",
    "shortlist = filelist\n",
    "df_list = [pd.read_parquet(filepath+file) for file in shortlist]\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ed96e785-21cc-489e-9cc2-375ed25f03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Strings that end in hh:mm:ss\n",
    "# pattern = re.compile(\"-\\d\\d:\\d\\d:\\d\\d\")\n",
    "# timestamp_words = []\n",
    "# for i in range(len(df)):\n",
    "#     if pattern.search(df['text'][i]):\n",
    "#         timestamp_words.append(df['text'][i].partition('-')[0])\n",
    "\n",
    "# timestamp_words = pd.DataFrame(timestamp_words)\n",
    "# timestamp_words[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "d1fc9866-5f40-4603-a481-4d5d9801a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix timestamp words\n",
    "fix_list = ['Arvd', 'Clrd', 'Disp', 'Enrt']\n",
    "pattern = re.compile(\"-\\d\\d:\\d\\d:\\d\\d\")\n",
    "\n",
    "df['text2'] = df['text']\n",
    "df['timestamp'] = 0\n",
    "\n",
    "for i in range (len(df)):\n",
    "    if pattern.search(df['text'][i]):\n",
    "        df['timestamp'][i] = 1\n",
    "    for s in fix_list:\n",
    "        if (enchant.utils.levenshtein(df[\"text\"][i].partition('-')[0],s)<=2) and pattern.search(df['text'][i]):\n",
    "            df['text2'][i] = s +'-' + df[\"text\"][i].partition('-')[2]\n",
    "\n",
    "# Note - dist('Arvd','Clrd') = 3 so threshhold needs to be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c2e47b55-cd2a-4279-9ee2-6a8b0959bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = df[df['text2']!=df['text']]\n",
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b47709fc-ee96-4d0b-9092-6bab80ee97e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arvd', 'Clrd', 'Disp', 'Enrt', 'Arv@a@', 'Cirdad'], dtype=object)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timestamp text that did not get fixed\n",
    "df_ts = df[df['timestamp']==1]\n",
    "pattern = re.compile(\"-\\d\\d:\\d\\d:\\d\\d\")\n",
    "# df_ts['text_alpha'] = df_ts['text2'].str.replace(pattern,'', regex=True)\n",
    "df_ts['text_alpha'] = df_ts['text2'].str.partition(sep='-')[0]\n",
    "\n",
    "df_ts['text_alpha'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84359a02-eac1-415b-bb46-9f3a27925ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: Text clustering with k-means\n",
    "# https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html\n",
    "# Center = most frequent spelling?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
